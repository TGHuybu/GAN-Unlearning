{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DCGAN Training**\n",
    "\n",
    "Requires:\n",
    "- Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import networks as nws\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "# image_size = 28 # Mnist\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "workers = 2\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"MNIST_full\"\n",
    "# dataroot = \"MNIST_no1s\"\n",
    "\n",
    "if dataroot == \"MNIST_full\":\n",
    "    # We can use an image folder dataset the way we have it setup.\n",
    "    # Create the dataset\n",
    "    dataset = dset.MNIST(\n",
    "        root=dataroot,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ]),\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    # Create the dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    model_suffix = dataroot\n",
    "else:\n",
    "    dataset = dset.ImageFolder(\n",
    "        root=dataroot,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "            transforms.Resize((28, 28)), \n",
    "            transforms.Grayscale()\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Create the dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    model_suffix = dataroot\n",
    "\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết bị sử dụng\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#-- Tạo mạng G\n",
    "version = 3\n",
    "nz = 128\n",
    "\n",
    "netG = nws.Generator(version=version, nz=nz).to(device)\n",
    "netG.apply(nws.weights_init)\n",
    "\n",
    "#-- Tạo mạng D\n",
    "netD = nws.Discriminator(version=version).to(device)\n",
    "netD.apply(nws.weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_paramsG = sum(p.numel() for p in netG.parameters() if p.requires_grad)\n",
    "print(f\"GEN version {version}, # params {n_paramsG}\")\n",
    "# v1  312256\n",
    "# v2  316640\n",
    "\n",
    "# NOTE: DIS version match with GEN\n",
    "#   based on GEN's complexity\n",
    "n_paramsD = sum(p.numel() for p in netD.parameters() if p.requires_grad)\n",
    "print(f\"DIS version {version}, # params {n_paramsD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create a batch (64) of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "num_epochs = 300\n",
    "\n",
    "save_dir = \"checkpoints_original\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "plts_dir = f\"plots/GAN_train_{model_suffix}\"\n",
    "os.makedirs(plts_dir, exist_ok=True)\n",
    "\n",
    "c_optimizer = optimizerG.__class__.__name__ # Adam | SGD\n",
    "c_lr = str(optimizerD.param_groups[0]['lr']).replace(\".\", \"\") # 00002 | 00004 ...\n",
    "\n",
    "print(\"-- Epochs: \", num_epochs)\n",
    "print(\"-- Current z_dim: \", nz)\n",
    "print(\"-- Current optimizer & learning rate: \", c_optimizer, c_lr)\n",
    "print(\"-- Is training netG: \", netG.training)\n",
    "print(\"-- Is training netD: \", netD.training)\n",
    "print(\"-- Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "ttrain_D, ttrain_G, ttrain_GAN = 0, 0, 0\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, (data, _) in enumerate(dataloader):\n",
    "        # print(i)\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        tD_start = time.time()\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        tD_end = time.time()\n",
    "        ttrain_D += tD_end - tD_start\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        tG_start = time.time()\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        tG_end = time.time()\n",
    "        ttrain_G += tG_end - tG_start\n",
    "\n",
    "        ttrain_GAN = ttrain_D + ttrain_G\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch + 1, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 50 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Lưu trọng số G tại epoch 10 và 50\n",
    "    # if epoch == 10 or epoch == 50:\n",
    "    #     torch.save(netG.state_dict(), f\"{save_dir}/generator_epoch_{epoch}.pth\")\n",
    "\n",
    "print(f\">> GAN training time: {ttrain_GAN}\")\n",
    "print(f\"  -- Discriminator training time: {ttrain_D}\")\n",
    "print(f\"  -- Generator training time: {ttrain_G}\")\n",
    "\n",
    "torch.save(netG.state_dict(), f\"{save_dir}/gen_{model_suffix}_v{version}_nz={nz}_epochs={num_epochs}.pth\")\n",
    "torch.save(netD.state_dict(), f\"{save_dir}/dis_{model_suffix}_v{version}_nz={nz}_epochs={num_epochs}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "figname = f\"{plts_dir}/GAN_loss_{model_suffix}_v{version}_nz={nz}_epochs={num_epochs}.jpg\"\n",
    "plt.savefig(figname, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "\n",
    "figname = f\"{plts_dir}/Real_vs_Generated_{model_suffix}_v{version}_nz={nz}_epochs={num_epochs}.jpg\"\n",
    "plt.savefig(figname, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
