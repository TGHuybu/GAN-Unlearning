{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DCGAN Unlearning Metrics**\n",
    "\n",
    "Requires:\n",
    "- Full training dataset (if evaluate original model).\n",
    "- Desired dataset (obtained by removing the unwanted samples/class from the training data).\n",
    "- Original model.\n",
    "- Unlearned models (all 4 losses `inv`, `neg`, `exp`, and `ens`).\n",
    "- Retrained model using desired dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import networks as nws\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Thiết bị sử dụng\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load DCGAN models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model location\n",
    "original_train_epochs = 300\n",
    "original_save_dir = \"checkpoints_original\"\n",
    "\n",
    "# Choose an undesired class\n",
    "ul_class = 8  # `1` or `8`\n",
    "\n",
    "# Unlearned model location\n",
    "do_mask = True\n",
    "ckpt_dir_suffix = \"_mask\" if do_mask else \"\"\n",
    "dset_name = f\"MNIST_ul{ul_class}_data\"\n",
    "ckpt_dir = f\"checkpoints_unlearn{ckpt_dir_suffix}\"\n",
    "\n",
    "# Hyperparams for all the repulsion loss\n",
    "rlweight_inv, rlweight_neg, rlweight_exp, rlweight_ens = 5, 1, 20, 20\n",
    "epochs_inv, epochs_neg, epochs_exp, epochs_ens = 5, 300, 300, 300\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_original.load_state_dict(torch.load(f'{original_save_dir}/gen_MNIST_full_v{version}_nz={nz}_epochs={original_train_epochs}.pth'))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_retrained_desired.load_state_dict(torch.load(f'{original_save_dir}/gen_MNIST_without_{ul_class}s_v{version}_nz={nz}_epochs={original_train_epochs}.pth'))  # change\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_unlearned_l2_inv.load_state_dict(torch.load(f'{ckpt_dir}/l2_inv/{dir_l2inv}/gen_unlearned_v3_nz=128_l2_inv.pth'))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_unlearned_l2_neg.load_state_dict(torch.load(f'{ckpt_dir}/l2_neg/{dir_l2neg}/gen_unlearned_v3_nz=128_l2_neg.pth'))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_unlearned_l2_exp.load_state_dict(torch.load(f'{ckpt_dir}/l2_exp/{dir_l2exp}/gen_unlearned_v3_nz=128_l2_exp.pth'))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\269554296.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_unlearned_l2_ens.load_state_dict(torch.load(f'{ckpt_dir}/l2_ens/{dir_l2ens}/gen_unlearned_v3_nz=128_l2_ens.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz = 128\n",
    "version = 3\n",
    "\n",
    "G_original = nws.Generator(version=version).to(device)\n",
    "G_retrained_desired = nws.Generator(version=version).to(device)\n",
    "G_unlearned_l2_inv = nws.Generator(version=version).to(device)\n",
    "G_unlearned_l2_neg = nws.Generator(version=version).to(device)\n",
    "G_unlearned_l2_exp = nws.Generator(version=version).to(device)\n",
    "G_unlearned_l2_ens = nws.Generator(version=version).to(device)\n",
    "\n",
    "G_original.load_state_dict(torch.load(f'{original_save_dir}/gen_MNIST_full_v{version}_nz={nz}_epochs={original_train_epochs}.pth'))\n",
    "G_retrained_desired.load_state_dict(torch.load(f'{original_save_dir}/gen_MNIST_without_{ul_class}s_v{version}_nz={nz}_epochs={original_train_epochs}.pth'))  # change\n",
    "\n",
    "dir_l2inv = f\"rlweight={rlweight_inv}_alpha=None_epochs={epochs_inv}_dataset={dset_name}\"\n",
    "dir_l2neg = f\"rlweight={rlweight_neg}_alpha=None_epochs={epochs_neg}_dataset={dset_name}\"\n",
    "dir_l2exp = f\"rlweight={rlweight_exp}_alpha={alpha}_epochs={epochs_exp}_dataset={dset_name}\"\n",
    "dir_l2ens = f\"rlweight={rlweight_ens}_alpha={alpha}_epochs={epochs_ens}_dataset={dset_name}\"\n",
    "\n",
    "G_unlearned_l2_inv.load_state_dict(torch.load(f'{ckpt_dir}/l2_inv/{dir_l2inv}/gen_unlearned_v3_nz=128_l2_inv.pth'))\n",
    "G_unlearned_l2_neg.load_state_dict(torch.load(f'{ckpt_dir}/l2_neg/{dir_l2neg}/gen_unlearned_v3_nz=128_l2_neg.pth'))\n",
    "G_unlearned_l2_exp.load_state_dict(torch.load(f'{ckpt_dir}/l2_exp/{dir_l2exp}/gen_unlearned_v3_nz=128_l2_exp.pth'))\n",
    "G_unlearned_l2_ens.load_state_dict(torch.load(f'{ckpt_dir}/l2_ens/{dir_l2ens}/gen_unlearned_v3_nz=128_l2_ens.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13892\\4228288968.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load(f'classifier/mnist_classifier.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nws.CNN_Classifier().to(device)\n",
    "classifier.load_state_dict(torch.load(f'classifier/mnist_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Original GAN metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset = dset.MNIST(\n",
    "    root=\"MNIST_full\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create the dataloader\n",
    "original_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# print(len(original_dataloader))\n",
    "# print(len(original_dataloader.dataset))\n",
    "\n",
    "# features_original_list = []\n",
    "# count = 0\n",
    "# for i, (images, labels) in enumerate(original_dataloader):\n",
    "#     if count >= 12800: break\n",
    "#     features_original_list.append(utils.get_features(classifier, images))\n",
    "#     count += images.size(0)\n",
    "\n",
    "# features_original = np.concatenate(features_original_list, axis=0)\n",
    "# print(features_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1\n",
    "fids = utils.compute_FIDs(G_original, classifier, nz, device, dset_loader=original_dataloader, n_iters=n_iters)\n",
    "torch.cuda.empty_cache()\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_originalGAN_v{version}_nz={nz}_epochs={original_train_epochs}.txt\", fids)\n",
    "print(f\">> FID ({n_iters} iters): {fids.mean()} (err: {fids.std()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "\n",
    "# features_original_data_list = []\n",
    "# count = 0\n",
    "# for i, (images, labels) in enumerate(original_dataloader):\n",
    "#     if count >= 12800: break\n",
    "#     features_original_data_list.append(get_features(classifier, images))\n",
    "#     count += images.size(0)\n",
    "# features_original = np.concatenate(features_original_data_list, axis=0)\n",
    "\n",
    "# generated = generate_folder(G_original, examples=12800)\n",
    "# features_generated = get_features(classifier, generated)\n",
    "# X_original_GAN = np.concatenate([features_original, features_generated])\n",
    "# X_tsne_original_GAN = tsne.fit_transform(X_original_GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_tsne_original = X_tsne_original_GAN[0:12800+1]\n",
    "# ft_tsne_original_generated = X_tsne_original_GAN[12800+1:]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# ax[0].scatter(ft_tsne_original[:, 0], ft_tsne_original[:, 1], alpha=0.1)\n",
    "# ax[0].set_title(\"Original data (full class)\")\n",
    "# ax[1].scatter(ft_tsne_original_generated[:, 0], ft_tsne_original_generated[:, 1], alpha=0.1)\n",
    "# ax[1].set_title(\"Generated data (original GAN)\")\n",
    "\n",
    "# fig.set_size_inches((12, 6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unlean metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataset = dset.ImageFolder(\n",
    "    root=f\"MNIST_without_{ul_class}s\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        transforms.Resize((28, 28)), \n",
    "        transforms.Grayscale()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Create the dataloader\n",
    "desired_dset_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        shuffle=True)\n",
    "print(len(desired_dset_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compute PUL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> PUL l2_inv (1 iters): 75.1709626512362 (err: 0.0)\n",
      ">> PUL l2_neg (1 iters): 76.01931330472102 (err: 0.0)\n",
      ">> PUL l2_exp (1 iters): 77.2823779193206 (err: 0.0)\n",
      ">> PUL l2_exp (1 iters): 77.9596290234588 (err: 0.0)\n"
     ]
    }
   ],
   "source": [
    "n_iters = 1   # ---> Set to >1 if measure multiple times\n",
    "puls_l2inv = utils.compute_PULs(G_original, G_unlearned_l2_inv, classifier, ul_class, nz, device, n_iters=n_iters)\n",
    "puls_l2neg = utils.compute_PULs(G_original, G_unlearned_l2_neg, classifier, ul_class, nz, device, n_iters=n_iters)\n",
    "puls_l2exp = utils.compute_PULs(G_original, G_unlearned_l2_exp, classifier, ul_class, nz, device, n_iters=n_iters)\n",
    "puls_l2ens = utils.compute_PULs(G_original, G_unlearned_l2_exp, classifier, ul_class, nz, device, n_iters=n_iters)\n",
    "print(f\">> PUL l2_inv ({n_iters} iters): {puls_l2inv.mean()} (err: {puls_l2inv.std()})\")\n",
    "print(f\">> PUL l2_neg ({n_iters} iters): {puls_l2neg.mean()} (err: {puls_l2neg.std()})\")\n",
    "print(f\">> PUL l2_exp ({n_iters} iters): {puls_l2exp.mean()} (err: {puls_l2exp.std()})\")\n",
    "print(f\">> PUL l2_exp ({n_iters} iters): {puls_l2ens.mean()} (err: {puls_l2ens.std()})\")\n",
    "\n",
    "np.savetxt(f\"PUL_save/PUL_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2inv_nz={nz}_dset={dset_name}.txt\", puls_l2inv)\n",
    "np.savetxt(f\"PUL_save/PUL_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2neg_nz={nz}_dset={dset_name}.txt\", puls_l2neg)\n",
    "np.savetxt(f\"PUL_save/PUL_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2exp_nz={nz}_dset={dset_name}.txt\", puls_l2exp)\n",
    "np.savetxt(f\"PUL_save/PUL_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2ens_nz={nz}_dset={dset_name}.txt\", puls_l2ens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compute FID**\n",
    "- ref: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> FID retrained no 8 (1 iters): 21.090245077570014 (err: 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Retrained\n",
    "n_iters = 1   # ---> Set to >1 if measure multiple times\n",
    "fids_retrained = utils.compute_FIDs(G_retrained_desired, classifier, nz, device, dset_loader=desired_dset_dataloader, n_iters=n_iters)\n",
    "print(f\">> FID retrained no {ul_class} ({n_iters} iters): {fids_retrained.mean()} (err: {fids_retrained.std()})\")\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_retrainedGAN_v{version}_l2inv_nz={nz}_dset=MNIST_without_{ul_class}s.txt\", fids_retrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> FID l2_inv (1 iters): 166.1316368791977 (err: 0.0)\n",
      ">> FID l2_neg (1 iters): 48.95280833440727 (err: 0.0)\n",
      ">> FID l2_exp (1 iters): 51.22682271719442 (err: 0.0)\n",
      ">> FID l2_exp (1 iters): 48.90649580347077 (err: 0.0)\n"
     ]
    }
   ],
   "source": [
    "n_iters = 1   # ---> Set to >1 if measure multiple times\n",
    "fids_l2inv = utils.compute_FIDs(G_unlearned_l2_inv, classifier, nz, device, dset_loader=desired_dset_dataloader, n_iters=n_iters)\n",
    "fids_l2neg = utils.compute_FIDs(G_unlearned_l2_neg, classifier, nz, device, dset_loader=desired_dset_dataloader, n_iters=n_iters)\n",
    "fids_l2exp = utils.compute_FIDs(G_unlearned_l2_exp, classifier, nz, device, dset_loader=desired_dset_dataloader, n_iters=n_iters)\n",
    "fids_l2ens = utils.compute_FIDs(G_unlearned_l2_exp, classifier, nz, device, dset_loader=desired_dset_dataloader, n_iters=n_iters)\n",
    "print(f\">> FID l2_inv ({n_iters} iters): {fids_l2inv.mean()} (err: {fids_l2inv.std()})\")\n",
    "print(f\">> FID l2_neg ({n_iters} iters): {fids_l2neg.mean()} (err: {fids_l2neg.std()})\")\n",
    "print(f\">> FID l2_exp ({n_iters} iters): {fids_l2exp.mean()} (err: {fids_l2exp.std()})\")\n",
    "print(f\">> FID l2_exp ({n_iters} iters): {fids_l2ens.mean()} (err: {fids_l2ens.std()})\")\n",
    "\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2inv_nz={nz}_dset={dset_name}.txt\", fids_l2inv)\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2neg_nz={nz}_dset={dset_name}.txt\", fids_l2neg)\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2exp_nz={nz}_dset={dset_name}.txt\", fids_l2exp)\n",
    "np.savetxt(f\"FID_save/FID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2ens_nz={nz}_dset={dset_name}.txt\", fids_l2ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Ret-FID l2_inv (1 iters): 182.6613977219073 (err: 0.0)\n",
      ">> Ret-FID l2_neg (1 iters): 59.44633157416936 (err: 0.0)\n",
      ">> Ret-FID l2_exp (1 iters): 67.97716664634336 (err: 0.0)\n",
      ">> Ret-FID l2_exp (1 iters): 67.17950681242627 (err: 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Ret-FID\n",
    "n_iters = 1   # ---> Set to >1 if measure multiple times\n",
    "retfids_l2inv = utils.compute_FIDs(G_unlearned_l2_inv, classifier, nz, device, model2=G_retrained_desired, n_iters=n_iters)\n",
    "retfids_l2neg = utils.compute_FIDs(G_unlearned_l2_neg, classifier, nz, device, model2=G_retrained_desired, n_iters=n_iters)\n",
    "retfids_l2exp = utils.compute_FIDs(G_unlearned_l2_exp, classifier, nz, device, model2=G_retrained_desired, n_iters=n_iters)\n",
    "retfids_l2ens = utils.compute_FIDs(G_unlearned_l2_exp, classifier, nz, device, model2=G_retrained_desired, n_iters=n_iters)\n",
    "print(f\">> Ret-FID l2_inv ({n_iters} iters): {retfids_l2inv.mean()} (err: {retfids_l2inv.std()})\")\n",
    "print(f\">> Ret-FID l2_neg ({n_iters} iters): {retfids_l2neg.mean()} (err: {retfids_l2neg.std()})\")\n",
    "print(f\">> Ret-FID l2_exp ({n_iters} iters): {retfids_l2exp.mean()} (err: {retfids_l2exp.std()})\")\n",
    "print(f\">> Ret-FID l2_exp ({n_iters} iters): {retfids_l2ens.mean()} (err: {retfids_l2ens.std()})\")\n",
    "\n",
    "np.savetxt(f\"FID_save/RetFID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2inv_nz={nz}_dset={dset_name}.txt\", retfids_l2inv)\n",
    "np.savetxt(f\"FID_save/RetFID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2neg_nz={nz}_dset={dset_name}.txt\", retfids_l2neg)\n",
    "np.savetxt(f\"FID_save/RetFID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2exp_nz={nz}_dset={dset_name}.txt\", retfids_l2exp)\n",
    "np.savetxt(f\"FID_save/RetFID_niters={n_iters}_unlearnedGAN{ckpt_dir_suffix}_v{version}_l2ens_nz={nz}_dset={dset_name}.txt\", retfids_l2ens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
